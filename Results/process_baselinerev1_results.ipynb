{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script processes the rev1 results \n",
    "\n",
    "1. Compile rev1 with:\n",
    "```\n",
    "make bin/baseline-rev1\n",
    "make bin/baseline-rev1collap\n",
    "```\n",
    "2. Run the benchmarking script\n",
    "```\n",
    "cd scripts\n",
    "python run_par_baseline-rev1.py\n",
    "```\n",
    "3. These are the outputs of the benchmarking script that will be processed, and should be already in the `Results` directory:\n",
    "```\n",
    "baseline-rev1_<hostname>.txt\n",
    "baseline-rev1_collapse_<hostname>.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get the hostname of the server\n",
    "hostname = os.popen(\"hostname\").read().strip()\n",
    "# ensure the directory exists\n",
    "os.makedirs(hostname, exist_ok=True)\n",
    "# ensure the files exist\n",
    "file_list = [                   \n",
    "                f'baseline-rev1_{hostname}.txt', f'baseline-rev1_collapse_{hostname}.txt', # dynamic\n",
    "            ]\n",
    "\n",
    "for rev1_file in file_list:\n",
    "    # if it is not in Results\n",
    "    if not os.path.exists(rev1_file):\n",
    "        # is the file already in the directory?\n",
    "        assert os.path.exists(os.path.join(hostname, rev1_file)), f'File {rev1_file} not found: something went wrong with the baseline benchmark.'\n",
    "    # if it is in Results\n",
    "    else:\n",
    "        # copy the file to the directory\n",
    "        assert os.system(f'mv {rev1_file} {hostname}/') == 0, f'Failed to move {rev1_file} to {hostname}/'\n",
    "# add the path to all the names in the list\n",
    "for i in range(len(file_list)):\n",
    "    file_list[i] = os.path.join(hostname, file_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import sys\n",
    "from statistics import mean\n",
    "from common.utils import get_nprocs, get_best_level\n",
    "\n",
    "# number of threads used in the execution\n",
    "num_threads = get_nprocs()\n",
    "# get the maximum number of threads as reference\n",
    "maxth = max(num_threads) # num_threads[-1]\n",
    "\n",
    "def tokenize_baseline(file):\n",
    "    experiment ={}\n",
    "\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            if \"Running:\" in tokens:\n",
    "                name=tokens[2].split(\"/\")[-1]\n",
    "                nth=int(tokens[6])\n",
    "                # get the chunk size used in the scheduler\n",
    "                chunksize = int(tokens[8])\n",
    "                if name not in experiment:\n",
    "                    experiment[name]={}\n",
    "                # if chunksize is not in the dictionary, add it\n",
    "                if chunksize not in experiment[name]:\n",
    "                    experiment[name][chunksize]={}\n",
    "                # if the number of threads is not in the dictionary, add it\n",
    "                if nth not in experiment[name][chunksize]:\n",
    "                    experiment[name][chunksize][nth]={}\n",
    "                    # initialize the list of stage times\n",
    "                    experiment[name][chunksize][nth]['stages']=[]                \n",
    "\n",
    "            if 'Octree' in tokens:\n",
    "                experiment[name][chunksize][nth]['octree'] = float(tokens[5])\n",
    "            if \"STAGE\" in tokens:\n",
    "                experiment[name][chunksize][nth]['stages'].append(float(tokens[5]))\n",
    "            if 'Average:' in tokens:\n",
    "                experiment[name][chunksize][nth]['owm'] = float(tokens[1])\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # for each cloud\n",
    "    for cloud in experiment:\n",
    "        results[cloud] = {}\n",
    "        # for each chunk size\n",
    "        for chunk in experiment[cloud]:\n",
    "            results[cloud][chunk] = {}\n",
    "            # for each number of threads\n",
    "            for nth in experiment[cloud][chunk]:\n",
    "                results[cloud][chunk][nth] = {}\n",
    "                # the first element in the list is the time of building the octree\n",
    "                results[cloud][chunk][nth]['octree'] = experiment[cloud][chunk][nth]['octree']\n",
    "                # the next three elements are the time of the stages 1, 2 and 3; one time for each of three elements\n",
    "                results[cloud][chunk][nth]['stage1'] = mean(experiment[cloud][chunk][nth]['stages'][0::3])\n",
    "                results[cloud][chunk][nth]['stage2'] = mean(experiment[cloud][chunk][nth]['stages'][1::3])\n",
    "                results[cloud][chunk][nth]['stage3'] = mean(experiment[cloud][chunk][nth]['stages'][2::3])\n",
    "                # the last elment is the average time\n",
    "                results[cloud][chunk][nth]['owm'] = experiment[cloud][chunk][nth]['owm']\n",
    "                # keep total = octree + owm\n",
    "                results[cloud][chunk][nth]['total'] = results[cloud][chunk][nth]['octree'] + results[cloud][chunk][nth]['owm']\n",
    "\n",
    "    return results\n",
    "\n",
    "# dictionay with the results of the benchmark\n",
    "all_results = {}\n",
    "# get the results\n",
    "for file in file_list:\n",
    "    # get the key from the filename\n",
    "    all_results[file.replace(f'_{hostname}.txt', '').replace(f'{hostname}/','')] = tokenize_baseline(file)\n",
    "# porint to the dynamic\n",
    "brev1 = all_results['baseline-rev1']\n",
    "# point to the dynamic+collapse\n",
    "brev1collap = all_results['baseline-rev1_collapse']\n",
    "print(list(all_results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results in All_optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = os.path.join(hostname, f'All_Optimizations-{hostname}.csv')\n",
    "\n",
    "with open(output, \"a\") as f:\n",
    "    octree_t = []\n",
    "    for i,cloud in enumerate(brev1):\n",
    "        bestchunk = get_best_level(brev1, cloud, maxth, 'total')\n",
    "        octree_t.append(mean(list(brev1[cloud][bestchunk][j]['octree'] for j in num_threads)))\n",
    "        print(\"Base-REV1; {}; {:.5f}; {:.5f};{};{}\".format(cloud, octree_t[i], brev1[cloud][bestchunk][maxth]['owm'], bestchunk, 0))\n",
    "        f.write(\"Base-REV1;{};{:.5f};{:.5f};{};{}\\n\".format(cloud, octree_t[i], brev1[cloud][bestchunk][maxth]['owm'], bestchunk, 0))    \n",
    "    octree_t = []\n",
    "    for i,cloud in enumerate(brev1collap):\n",
    "        bestchunk = get_best_level(brev1collap, cloud, maxth, 'total')\n",
    "        octree_t.append(mean(list(brev1collap[cloud][bestchunk][j]['octree'] for j in num_threads)))\n",
    "        print(\"Base-REV1collap; {}; {:.5f}; {:.5f};{};{}\".format(cloud, octree_t[i], brev1collap[cloud][bestchunk][maxth]['owm'], bestchunk, 0))\n",
    "        f.write(\"Base-REV1collap;{};{:.5f};{:.5f};{};{}\\n\".format(cloud, octree_t[i], brev1collap[cloud][bestchunk][maxth]['owm'], bestchunk, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-intel",
   "language": "python",
   "name": "venv-intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
